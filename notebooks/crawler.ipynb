{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "17fb04da",
      "metadata": {
        "id": "17fb04da"
      },
      "source": [
        "# Crawler"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "457822ea",
      "metadata": {
        "id": "457822ea"
      },
      "source": [
        "[Click here to run this chapter on Colab](https://colab.research.google.com/github/AllenDowney/DSIRP/blob/main/notebooks/crawler.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e5cbc301",
      "metadata": {
        "id": "e5cbc301"
      },
      "source": [
        "## Crawling the web\n",
        "\n",
        "At this point we have all the pieces we need to build a web crawler; it's time to bring them together.\n",
        "\n",
        "First, from `philosophy.ipynb`, we have `WikiFetcher`, which we'll use to download pages from Wikipedia while limiting requests to about one per second."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a9a87a52",
      "metadata": {
        "id": "a9a87a52"
      },
      "outputs": [],
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "from time import time, sleep\n",
        "\n",
        "class WikiFetcher:\n",
        "    next_request_time = None\n",
        "    min_interval = 1  # second\n",
        "\n",
        "    def fetch_wikipedia(self, url):\n",
        "        self.sleep_if_needed()\n",
        "        fp = urlopen(url)\n",
        "        soup = BeautifulSoup(fp, 'html.parser')\n",
        "        return soup\n",
        "\n",
        "    def sleep_if_needed(self):\n",
        "        if self.next_request_time:\n",
        "            sleep_time = self.next_request_time - time()\n",
        "            if sleep_time > 0:\n",
        "                sleep(sleep_time)\n",
        "\n",
        "        self.next_request_time = time() + self.min_interval"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ebc98c7",
      "metadata": {
        "id": "5ebc98c7"
      },
      "source": [
        "Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "ca8689bc",
      "metadata": {
        "id": "ca8689bc"
      },
      "outputs": [],
      "source": [
        "fetcher = WikiFetcher()\n",
        "\n",
        "url = 'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
        "soup = fetcher.fetch_wikipedia(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4799dd28",
      "metadata": {
        "id": "4799dd28"
      },
      "source": [
        "The result is a BeautifulSoup object that represents the document object model (DOM) of the page.\n",
        "\n",
        "Note that `WikiFetcher` won't work if `url` is a bytearray, because `urlopen` doesn't work with bytearrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f7876a10",
      "metadata": {
        "id": "f7876a10"
      },
      "outputs": [],
      "source": [
        "url = b'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
        "# soup = fetcher.fetch_wikipedia(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "112bd118",
      "metadata": {
        "id": "112bd118"
      },
      "source": [
        "To convert a bytearray to a string, you have to decode it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "51206d5e",
      "metadata": {
        "id": "51206d5e"
      },
      "outputs": [],
      "source": [
        "url_str = url.decode()\n",
        "soup = fetcher.fetch_wikipedia(url_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "150d2b05",
      "metadata": {
        "id": "150d2b05"
      },
      "source": [
        "Usually when you call `decode`, you should [specify which encoding to use](https://docs.python.org/3.8/library/stdtypes.html#bytes.decode). But in this case we know that the original strings were URLs, so the default encoding will work.\n",
        "\n",
        "Wikipedia pages contain boilerplate content that we don't want to index, so we'll select the `div` element that contains the \"body content\" of the page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "118a5b1e",
      "metadata": {
        "id": "118a5b1e"
      },
      "outputs": [],
      "source": [
        "root = soup.find(class_='mw-body-content')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72873ecb",
      "metadata": {
        "id": "72873ecb"
      },
      "source": [
        "## Finding links\n",
        "\n",
        "From `philosophy.ipynb`, we have the following function that traverses the DOM and finds links."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ec3146d4",
      "metadata": {
        "id": "ec3146d4"
      },
      "outputs": [],
      "source": [
        "from bs4 import Tag\n",
        "\n",
        "def link_generator(root):\n",
        "    for element in root.descendants:\n",
        "        if isinstance(element, Tag) and element.name == 'a':\n",
        "            href = element.get('href', '')\n",
        "            if href.startswith('/wiki'):\n",
        "                yield element"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e63ece98",
      "metadata": {
        "id": "e63ece98"
      },
      "source": [
        "This version includes links to images and other links we probably don't want to index.\n",
        "\n",
        "The following version includes a condition that checks whether the link has a `title` attribute, which seems to select mostly \"good\" links."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "35541f47",
      "metadata": {
        "id": "35541f47"
      },
      "outputs": [],
      "source": [
        "def link_generator(root):\n",
        "    for element in root.descendants:\n",
        "        if isinstance(element, Tag) and element.name == 'a':\n",
        "            title = element.get('title', '')\n",
        "            href = element.get('href', '')\n",
        "            if title and href.startswith('/wiki'):\n",
        "                yield element"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "680a9f82",
      "metadata": {
        "id": "680a9f82"
      },
      "source": [
        "Here are the first few links from the page we downloaded."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "d50e3acb",
      "metadata": {
        "id": "d50e3acb",
        "outputId": "39bde604-51ac-41a9-8949-99f284183c1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<a href=\"/wiki/Programming_paradigm\" title=\"Programming paradigm\">Paradigm</a>\n",
            "<a class=\"mw-redirect\" href=\"/wiki/Multi-paradigm\" title=\"Multi-paradigm\">Multi-paradigm</a>\n",
            "<a href=\"/wiki/Object-oriented_programming\" title=\"Object-oriented programming\">object-oriented</a>\n",
            "<a href=\"/wiki/Procedural_programming\" title=\"Procedural programming\">procedural</a>\n",
            "<a href=\"/wiki/Imperative_programming\" title=\"Imperative programming\">imperative</a>\n",
            "<a href=\"/wiki/Functional_programming\" title=\"Functional programming\">functional</a>\n"
          ]
        }
      ],
      "source": [
        "for i, link in enumerate(link_generator(root)):\n",
        "    print(link)\n",
        "    if i == 5:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3decf3bc",
      "metadata": {
        "id": "3decf3bc"
      },
      "source": [
        "## Finding words\n",
        "\n",
        "From `indexer.ipynb`, we have the following function, which traverses the DOM and yields individual words, stripped of punctuation and converted to lowercase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e7b75e21",
      "metadata": {
        "id": "e7b75e21"
      },
      "outputs": [],
      "source": [
        "from bs4 import NavigableString\n",
        "from string import whitespace, punctuation\n",
        "\n",
        "def iterate_words(root):\n",
        "    for element in root.descendants:\n",
        "        if isinstance(element, NavigableString):\n",
        "            for word in element.string.split():\n",
        "                word = word.strip(whitespace + punctuation)\n",
        "                if word:\n",
        "                    yield word.lower()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afe0c90b",
      "metadata": {
        "id": "afe0c90b"
      },
      "source": [
        "Here are the first words from the page we downloaded. They include keywords from the sidebar on the right side of the page, which are not part of the main text, but might be good to index anyway, since they indicate the topic of the page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "fc352e10",
      "metadata": {
        "collapsed": true,
        "id": "fc352e10",
        "outputId": "8b91445a-0b10-4ecb-82ae-4b7fd459aff3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "general-purpose\n",
            "programming\n",
            "language\n",
            "mw-parser-output\n",
            "hlist\n",
            "dl,.mw-parser-output\n",
            "hlist\n",
            "ol,.mw-parser-output\n",
            "hlist\n",
            "ul{margin:0;padding:0}.mw-parser-output\n",
            "hlist\n",
            "dd,.mw-parser-output\n",
            "hlist\n",
            "dt,.mw-parser-output\n",
            "hlist\n",
            "li{margin:0;display:inline}.mw-parser-output\n",
            "hlist.inline,.mw-parser-output\n",
            "hlist.inline\n",
            "dl,.mw-parser-output\n",
            "hlist.inline\n",
            "ol,.mw-parser-output\n",
            "hlist.inline\n",
            "ul,.mw-parser-output\n",
            "hlist\n",
            "dl\n",
            "dl,.mw-parser-output\n",
            "hlist\n",
            "dl\n",
            "ol,.mw-parser-output\n",
            "hlist\n",
            "dl\n",
            "ul,.mw-parser-output\n",
            "hlist\n",
            "ol\n",
            "dl,.mw-parser-output\n",
            "hlist\n",
            "ol\n",
            "ol,.mw-parser-output\n",
            "hlist\n",
            "ol\n",
            "ul,.mw-parser-output\n",
            "hlist\n",
            "ul\n",
            "dl,.mw-parser-output\n",
            "hlist\n",
            "ul\n",
            "ol,.mw-parser-output\n",
            "hlist\n",
            "ul\n",
            "ul{display:inline}.mw-parser-output\n",
            "hlist\n",
            "mw-empty-li{display:none}.mw-parser-output\n",
            "hlist\n",
            "dt::after{content\n",
            "mw-parser-output\n",
            "hlist\n",
            "dd::after,.mw-parser-output\n",
            "hlist\n",
            "li::after{content\n",
            "·\n",
            "font-weight:bold}.mw-parser-output\n",
            "hlist\n",
            "dd:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dt:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "li:last-child::after{content:none}.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "dd:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "dt:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "li:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "dd:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "dt:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "li:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "dd:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "dt:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "li:first-child::before{content\n",
            "font-weight:normal}.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "dd:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "dt:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "li:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "dd:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "dt:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "li:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "dd:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "dt:last-child::after,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output\n",
            "hlist\n",
            "ol{counter-reset:listitem}.mw-parser-output\n",
            "hlist\n",
            "ol>li{counter-increment:listitem}.mw-parser-output\n",
            "hlist\n",
            "ol>li::before{content\n",
            "counter(listitem)\"\\a0\n",
            "mw-parser-output\n",
            "hlist\n",
            "dd\n",
            "ol>li:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "dt\n",
            "ol>li:first-child::before,.mw-parser-output\n",
            "hlist\n",
            "li\n",
            "ol>li:first-child::before{content\n",
            "counter(listitem)\"\\a0\n",
            "mw-parser-output\n",
            "infobox-subbox{padding:0;border:none;margin:-3px;width:auto;min-width:100%;font-size:100%;clear:none;float:none;background-color:transparent}.mw-parser-output\n",
            "infobox-3cols-child{margin:auto}.mw-parser-output\n",
            "infobox\n",
            "navbar{font-size:100%}@media\n",
            "screen{html.skin-theme-clientpref-night\n",
            "mw-parser-output\n",
            "infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media\n",
            "screen\n",
            "and\n",
            "prefers-color-scheme:dark){html.skin-theme-clientpref-os\n",
            "mw-parser-output\n",
            "infobox-full-data:not(.notheme)>div:not(.notheme)[style]{background:#1f1f23!important;color:#f8f9fa}}@media(min-width:640px){body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table{display:table!important}body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table>caption{display:table-caption!important}body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table>tbody{display:table-row-group}body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table\n",
            "th,body.skin--responsive\n",
            "mw-parser-output\n",
            "infobox-table\n",
            "td{padding-left:inherit;padding-right:inherit\n",
            "python\n",
            "paradigm\n",
            "multi-paradigm\n",
            "object-oriented\n",
            "1\n",
            "procedural\n",
            "imperative\n",
            "functional\n",
            "structured\n",
            "reflective\n",
            "designed\n",
            "by\n",
            "guido\n",
            "van\n",
            "rossum\n",
            "developer\n",
            "python\n",
            "software\n",
            "foundation\n",
            "first\n",
            "appeared\n",
            "20\n",
            "february\n",
            "1991\n",
            "34\n",
            "years\n",
            "ago\n",
            "1991-02-20\n",
            "2\n",
            "stable\n",
            "release\n",
            "3.13.7\n",
            "3\n",
            "14\n",
            "august\n",
            "2025\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "for i, word in enumerate(iterate_words(root)):\n",
        "    print(word)\n",
        "    if i > 200:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbfd17ff",
      "metadata": {
        "id": "fbfd17ff"
      },
      "source": [
        "## Redis\n",
        "\n",
        "Let's get Redis started."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "1cbe8a49",
      "metadata": {
        "id": "1cbe8a49",
        "outputId": "d7af81e9-da40-4ba5-a0d8-506b50fef601",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-tools\n",
            "Suggested packages:\n",
            "  ruby-redis\n",
            "The following NEW packages will be installed:\n",
            "  libjemalloc2 liblua5.1-0 liblzf1 lua-bitop lua-cjson redis-server\n",
            "  redis-tools\n",
            "0 upgraded, 7 newly installed, 0 to remove and 74 not upgraded.\n",
            "Need to get 1,273 kB of archives.\n",
            "After this operation, 5,725 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libjemalloc2 amd64 5.2.1-4ubuntu1 [240 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblua5.1-0 amd64 5.1.5-8.1build4 [99.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 liblzf1 amd64 3.6-3 [7,444 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-bitop amd64 1.0.2-5 [6,680 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lua-cjson amd64 2.1.0+dfsg-2.1 [17.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 redis-tools amd64 5:6.0.16-1ubuntu1 [856 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 redis-server amd64 5:6.0.16-1ubuntu1 [45.9 kB]\n",
            "Fetched 1,273 kB in 0s (5,047 kB/s)\n",
            "Selecting previously unselected package libjemalloc2:amd64.\n",
            "(Reading database ... 126371 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libjemalloc2_5.2.1-4ubuntu1_amd64.deb ...\n",
            "Unpacking libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Selecting previously unselected package liblua5.1-0:amd64.\n",
            "Preparing to unpack .../1-liblua5.1-0_5.1.5-8.1build4_amd64.deb ...\n",
            "Unpacking liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Selecting previously unselected package liblzf1:amd64.\n",
            "Preparing to unpack .../2-liblzf1_3.6-3_amd64.deb ...\n",
            "Unpacking liblzf1:amd64 (3.6-3) ...\n",
            "Selecting previously unselected package lua-bitop:amd64.\n",
            "Preparing to unpack .../3-lua-bitop_1.0.2-5_amd64.deb ...\n",
            "Unpacking lua-bitop:amd64 (1.0.2-5) ...\n",
            "Selecting previously unselected package lua-cjson:amd64.\n",
            "Preparing to unpack .../4-lua-cjson_2.1.0+dfsg-2.1_amd64.deb ...\n",
            "Unpacking lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Selecting previously unselected package redis-tools.\n",
            "Preparing to unpack .../5-redis-tools_5%3a6.0.16-1ubuntu1_amd64.deb ...\n",
            "Unpacking redis-tools (5:6.0.16-1ubuntu1) ...\n",
            "Selecting previously unselected package redis-server.\n",
            "Preparing to unpack .../6-redis-server_5%3a6.0.16-1ubuntu1_amd64.deb ...\n",
            "Unpacking redis-server (5:6.0.16-1ubuntu1) ...\n",
            "Setting up libjemalloc2:amd64 (5.2.1-4ubuntu1) ...\n",
            "Setting up lua-cjson:amd64 (2.1.0+dfsg-2.1) ...\n",
            "Setting up liblzf1:amd64 (3.6-3) ...\n",
            "Setting up lua-bitop:amd64 (1.0.2-5) ...\n",
            "Setting up liblua5.1-0:amd64 (5.1.5-8.1build4) ...\n",
            "Setting up redis-tools (5:6.0.16-1ubuntu1) ...\n",
            "Setting up redis-server (5:6.0.16-1ubuntu1) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Created symlink /etc/systemd/system/redis.service → /lib/systemd/system/redis-server.service.\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/redis-server.service → /lib/systemd/system/redis-server.service.\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Use apt-get inside Colab, not pip\n",
        "    !apt-get update -qq\n",
        "    !apt-get install -y redis-server\n",
        "    !redis-server --daemonize yes\n",
        "else:\n",
        "    !redis-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa23066c",
      "metadata": {
        "id": "aa23066c"
      },
      "source": [
        "And make sure the Redis client is installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "68fecf23",
      "metadata": {
        "id": "68fecf23",
        "outputId": "a1207864-ca8e-4c6e-8b92-b66e67a264d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting redis\n",
            "  Downloading redis-6.4.0-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading redis-6.4.0-py3-none-any.whl (279 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/279.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/279.8 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.8/279.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: redis\n",
            "Successfully installed redis-6.4.0\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    import redis\n",
        "except ImportError:\n",
        "    !pip install redis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "99acc3db",
      "metadata": {
        "id": "99acc3db"
      },
      "source": [
        "We'll make a `Redis` object that creates the connection to the Redis database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "5e35a4cd",
      "metadata": {
        "id": "5e35a4cd"
      },
      "outputs": [],
      "source": [
        "import redis\n",
        "\n",
        "r = redis.Redis()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74cd2e6d",
      "metadata": {
        "id": "74cd2e6d"
      },
      "source": [
        "If you have a Redis database running on a different machine, you can create a `Redis` object using the URL of the database, like this\n",
        "\n",
        "```\n",
        "url = 'redis://redistogo:example@dory.redistogo.com:10534/'\n",
        "r = redis.Redis.from_url(url)\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12d92512",
      "metadata": {
        "id": "12d92512"
      },
      "source": [
        "If your database contains values from previous exercises, or if you make a mistake and want to start over, you can use the following function to clear the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8e2889b7",
      "metadata": {
        "id": "8e2889b7"
      },
      "outputs": [],
      "source": [
        "def clear_redis(r):\n",
        "    for key in r.keys():\n",
        "        r.delete(key)\n",
        "\n",
        "# clear_redis(r)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4819b593",
      "metadata": {
        "id": "4819b593"
      },
      "source": [
        "## Indexing\n",
        "\n",
        "From `indexer.ipynb`, here's the function that counts the words on a page and adds the results to a Redis hash.\n",
        "\n",
        "For each word, it creates or updates a hash in the database that maps from URLs to word counts. For example if the word `python` appears 428 times on a page, we could find the hash with key `Index:python` and add an entry that maps from the URL to the number 428."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cae0f2ea",
      "metadata": {
        "id": "cae0f2ea"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from collections import Counter\n",
        "\n",
        "def redis_index(root, url):\n",
        "    counter = Counter(iterate_words(root))\n",
        "    for word, count in counter.items():\n",
        "        if count >= 3:\n",
        "            key = f'Index:{word}'\n",
        "            # print(key, count)\n",
        "            r.hset(key, url, count)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05478a4f",
      "metadata": {
        "id": "05478a4f"
      },
      "source": [
        "The previous version is likely to be slow because it makes many small requests to the database.\n",
        "We can speed it up using a pipeline object, like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7f5f3919",
      "metadata": {
        "tags": [],
        "id": "7f5f3919"
      },
      "outputs": [],
      "source": [
        "def redis_index_pipeline(root, url):\n",
        "    counter = Counter(iterate_words(root))\n",
        "    p = r.pipeline(transaction=False)\n",
        "    for word, count in counter.items():\n",
        "        if count >= 3:\n",
        "            key = f'Index:{word}'\n",
        "            # print(key, count)\n",
        "            p.hset(key, url, count)\n",
        "    p.execute()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ddb5a5a",
      "metadata": {
        "id": "0ddb5a5a"
      },
      "source": [
        "Let's see which version is faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "4e09700f",
      "metadata": {
        "id": "4e09700f"
      },
      "outputs": [],
      "source": [
        "url = 'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
        "soup = fetcher.fetch_wikipedia(url)\n",
        "root = soup.find(class_='mw-body-content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "a8c478d2",
      "metadata": {
        "id": "a8c478d2",
        "outputId": "de244faa-9d52-4d47-d674-5a87f7caf847",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 76 ms, sys: 13.2 ms, total: 89.1 ms\n",
            "Wall time: 117 ms\n"
          ]
        }
      ],
      "source": [
        "%time redis_index(root, url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "36dc8ba4",
      "metadata": {
        "id": "36dc8ba4",
        "outputId": "5b85223d-16fd-4ff7-a0a9-45b06489d413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 26.3 ms, sys: 0 ns, total: 26.3 ms\n",
            "Wall time: 27.8 ms\n"
          ]
        }
      ],
      "source": [
        "%time redis_index_pipeline(root, url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6bb330",
      "metadata": {
        "id": "cf6bb330"
      },
      "source": [
        "We can use `hscan_iter` to iterate the field-values pairs in the index for the word `python`, and print the URLs of the pages where this word appears and the number of times it appears on each page."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "f160da90",
      "metadata": {
        "id": "f160da90"
      },
      "outputs": [],
      "source": [
        "key = f'Index:python'\n",
        "\n",
        "for page, count in r.hscan_iter(key):\n",
        "    print(page, count)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "969b9a52",
      "metadata": {
        "id": "969b9a52"
      },
      "source": [
        "Notice that when we get the number back, it's a bytearray. If we want to work with it as a number, we have to convert back to int."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d33be5a",
      "metadata": {
        "id": "4d33be5a"
      },
      "source": [
        "## Crawling\n",
        "\n",
        "In `philosophy.ipynb` we wrote a simple crawler that always follows the first link."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f89bb928",
      "metadata": {
        "id": "f89bb928"
      },
      "outputs": [],
      "source": [
        "from urllib.parse import urljoin\n",
        "\n",
        "target = 'https://en.wikipedia.org/wiki/Philosophy'\n",
        "\n",
        "def get_to_philosophy(url):\n",
        "    visited = []\n",
        "\n",
        "    for i in range(20):\n",
        "        if url == target:\n",
        "            print(f'Got there in {i} steps!')\n",
        "            return visited\n",
        "\n",
        "        if url in visited:\n",
        "            raise ValueError(f'URL already visited {url}')\n",
        "        else:\n",
        "            print(url)\n",
        "            visited.append(url)\n",
        "\n",
        "        soup = fetcher.fetch_wikipedia(url)\n",
        "        root = soup.find(class_='mw-body-content')\n",
        "        link = next(link_generator(root))\n",
        "        url = urljoin(url, link['href'])\n",
        "\n",
        "    return visited"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "15984fde",
      "metadata": {
        "id": "15984fde",
        "outputId": "bbd00897-9033-44c0-bfad-e0206c5467e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://en.wikipedia.org/wiki/Python_(programming_language)\n",
            "https://en.wikipedia.org/wiki/Programming_paradigm\n",
            "https://en.wikipedia.org/wiki/Programming_model\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "URL already visited https://en.wikipedia.org/wiki/Programming_paradigm",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1601292495.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_to_philosophy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-1250407340.py\u001b[0m in \u001b[0;36mget_to_philosophy\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0murl\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvisited\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'URL already visited {url}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: URL already visited https://en.wikipedia.org/wiki/Programming_paradigm"
          ]
        }
      ],
      "source": [
        "get_to_philosophy(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ab7dff8",
      "metadata": {
        "id": "7ab7dff8"
      },
      "source": [
        "Now we want a crawler that runs a breadth-first search.\n",
        "Here's the implementation of BFS from `bfs.ipynb`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "f09fa05c",
      "metadata": {
        "id": "f09fa05c"
      },
      "outputs": [],
      "source": [
        "from collections import deque\n",
        "\n",
        "def reachable_nodes_bfs(G, start):\n",
        "    seen = set()\n",
        "    queue = deque([start])\n",
        "    while queue:\n",
        "        node = queue.popleft()\n",
        "        if node not in seen:\n",
        "            seen.add(node)\n",
        "            neighbors = set(G[node]) - seen\n",
        "            queue.extend(neighbors)\n",
        "    return seen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76fc922f",
      "metadata": {
        "id": "76fc922f"
      },
      "source": [
        "\n",
        "**Exercise:** Write a function called `crawl` that takes a starting URL as a parameter, and an optional number of pages to crawl.\n",
        "\n",
        "It should create a queue of URLs and work it's way through the queue, indexing pages as it goes and adding new links to the queue.\n",
        "\n",
        "For a first draft, I suggest using Python data structures to keep track of the queue and the set of URLs that have already been seen/indexed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "73501f42",
      "metadata": {
        "id": "73501f42"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "\n",
        "def crawl(start_url, max_pages=10):\n",
        "    seen = {start_url}           # visited URLs\n",
        "    nextlevel = {start_url}      # BFS \"frontier\"\n",
        "    pages_crawled = 0\n",
        "\n",
        "    while nextlevel and pages_crawled < max_pages:\n",
        "        thislevel = nextlevel\n",
        "        nextlevel = set()\n",
        "\n",
        "        for url in thislevel:\n",
        "            print(f\"Crawling: {url}\")\n",
        "            try:\n",
        "                # fetch the page\n",
        "                response = requests.get(url, timeout=5)\n",
        "                if response.status_code != 200:\n",
        "                    continue\n",
        "\n",
        "                # parse HTML\n",
        "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "                pages_crawled += 1\n",
        "\n",
        "                # extract and enqueue new links\n",
        "                for link in soup.find_all(\"a\", href=True):\n",
        "                    absolute = urljoin(url, link[\"href\"])\n",
        "                    if absolute not in seen and absolute.startswith(\"http\"):\n",
        "                        seen.add(absolute)\n",
        "                        nextlevel.add(absolute)\n",
        "\n",
        "                if pages_crawled >= max_pages:\n",
        "                    break\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error fetching {url}: {e}\")\n",
        "\n",
        "    print(f\"✅ Done, crawled {pages_crawled} pages.\")\n",
        "    return seen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "1a291c9b",
      "metadata": {
        "id": "1a291c9b",
        "outputId": "4dc51766-4998-45e1-d8db-bc034a64b441",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crawling: https://en.wikipedia.org/wiki/Python_(programming_language)\n",
            "Crawling: https://en.wikipedia.org/wiki/Contributor_License_Agreement\n",
            "Crawling: https://en.wikipedia.org/wiki/Reference_implementation\n",
            "Crawling: https://web.archive.org/web/20181226141117/https://www.python.org/dev/peps/pep-0441/%20\n",
            "Crawling: https://en.wikipedia.org/wiki/Here_document\n",
            "Crawling: https://en.wikipedia.org/wiki/Pylons_(web_framework)\n",
            "Crawling: https://en.wikipedia.org/wiki/Python_(programming_language)#cite_ref-86\n",
            "Crawling: https://mail.python.org/pipermail/python-dev/2002-April/022739.html\n",
            "Crawling: https://en.wikipedia.org/wiki/Python_(programming_language)#cite_ref-AutoNT-93_228-0\n",
            "Crawling: https://en.wikipedia.org/wiki/Raku_(programming_language)\n",
            "Crawling: https://en.wikipedia.org/wiki/Python_(programming_language)#cite_ref-AutoNT-51_219-0\n",
            "✅ Done, crawled 10 pages.\n"
          ]
        }
      ],
      "source": [
        "url = 'https://en.wikipedia.org/wiki/Python_(programming_language)'\n",
        "seen = crawl(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "b168242e",
      "metadata": {
        "id": "b168242e"
      },
      "outputs": [],
      "source": [
        "key = 'Index:the'\n",
        "for page, count in r.hscan_iter(key):\n",
        "    print(page, count)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7c4c75d",
      "metadata": {
        "id": "e7c4c75d"
      },
      "source": [
        "For a second draft, consider storing these structures in Redis so they are persistent; that way, you can call `crawl` later and it will pick up from where it left off. Or you could have multiple crawlers running at the same time.\n",
        "\n",
        "Hint: When you read a URL from Redis, you might have to decode it to make a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "386785ec",
      "metadata": {
        "id": "386785ec"
      },
      "outputs": [],
      "source": [
        "queue_key = 'Crawler:queue'\n",
        "\n",
        "r.lpop(queue_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "6f26e885",
      "metadata": {
        "id": "6f26e885",
        "outputId": "22a7c363-2c8c-4743-eb07-b91931bbe8dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "seen_key = 'Crawler:seen'\n",
        "\n",
        "r.sismember(seen_key, 'anything')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "469b4d1d",
      "metadata": {
        "id": "469b4d1d"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import urljoin\n",
        "import redis\n",
        "\n",
        "# connect to Redis (adjust host/port if needed)\n",
        "r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
        "\n",
        "def crawl_persistent(start_url, max_pages=10):\n",
        "    # Initialize if queue is empty\n",
        "    if r.llen(\"to_crawl\") == 0 and not r.sismember(\"seen\", start_url):\n",
        "        r.rpush(\"to_crawl\", start_url)\n",
        "\n",
        "    pages_crawled = 0\n",
        "\n",
        "    while r.llen(\"to_crawl\") > 0 and pages_crawled < max_pages:\n",
        "        url = r.lpop(\"to_crawl\")  # dequeue\n",
        "        if url is None or r.sismember(\"seen\", url):\n",
        "            continue\n",
        "\n",
        "        print(f\"Crawling: {url}\")\n",
        "        try:\n",
        "            response = requests.get(url, timeout=5)\n",
        "            if response.status_code != 200:\n",
        "                continue\n",
        "\n",
        "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "            r.sadd(\"seen\", url)   # mark visited\n",
        "            pages_crawled += 1\n",
        "\n",
        "            # Store page text (optional index)\n",
        "            r.hset(\"pages\", url, soup.get_text()[:500])  # save first 500 chars\n",
        "\n",
        "            # enqueue new links\n",
        "            for link in soup.find_all(\"a\", href=True):\n",
        "                absolute = urljoin(url, link[\"href\"])\n",
        "                if absolute.startswith(\"http\") and not r.sismember(\"seen\", absolute):\n",
        "                    r.rpush(\"to_crawl\", absolute)\n",
        "\n",
        "            if pages_crawled >= max_pages:\n",
        "                break\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Error fetching {url}: {e}\")\n",
        "\n",
        "    print(f\"✅ Done, crawled {pages_crawled} pages.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "8405926a",
      "metadata": {
        "collapsed": true,
        "id": "8405926a",
        "outputId": "42427496-385e-4d65-9156-2f5d964c3182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crawling: https://en.wikipedia.org/wiki/Object-oriented_programming\n",
            "Crawling: https://en.wikipedia.org/wiki/Object-oriented_programming#bodyContent\n",
            "Crawling: https://en.wikipedia.org/wiki/Main_Page\n",
            "Crawling: https://en.wikipedia.org/wiki/Wikipedia:Contents\n",
            "Crawling: https://en.wikipedia.org/wiki/Portal:Current_events\n",
            "Crawling: https://en.wikipedia.org/wiki/Special:Random\n",
            "Crawling: https://en.wikipedia.org/wiki/Wikipedia:About\n",
            "Crawling: https://en.wikipedia.org/wiki/Wikipedia:Contact_us\n",
            "Crawling: https://en.wikipedia.org/wiki/Help:Contents\n",
            "Crawling: https://en.wikipedia.org/wiki/Help:Introduction\n",
            "Crawling: https://en.wikipedia.org/wiki/Wikipedia:Community_portal\n",
            "Crawling: https://en.wikipedia.org/wiki/Special:RecentChanges\n",
            "Crawling: https://en.wikipedia.org/wiki/Wikipedia:File_upload_wizard\n",
            "Crawling: https://en.wikipedia.org/wiki/Special:SpecialPages\n",
            "Crawling: https://en.wikipedia.org/wiki/Special:Search\n",
            "Crawling: https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en\n",
            "Crawling: https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Object-oriented+programming\n",
            "Crawling: https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Object-oriented+programming\n",
            "Crawling: https://donate.wikimedia.org/?wmf_source=donate&wmf_medium=sidebar&wmf_campaign=en.wikipedia.org&uselang=en\n",
            "Crawling: https://en.wikipedia.org/w/index.php?title=Special:CreateAccount&returnto=Object-oriented+programming\n",
            "Crawling: https://en.wikipedia.org/w/index.php?title=Special:UserLogin&returnto=Object-oriented+programming\n",
            "Crawling: https://en.wikipedia.org/wiki/Help:Introduction\n",
            "Crawling: https://en.wikipedia.org/wiki/Special:MyContributions\n",
            "Crawling: https://en.wikipedia.org/wiki/Special:MyTalk\n",
            "✅ Done, crawled 10 pages.\n"
          ]
        }
      ],
      "source": [
        "url = 'https://en.wikipedia.org/wiki/Object-oriented_programming'\n",
        "crawl_persistent(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "6eb7e394",
      "metadata": {
        "id": "6eb7e394",
        "outputId": "be77c536-22fd-427d-df70-101d69910249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "DataError",
          "evalue": "Invalid input of type: 'set'. Convert to a bytes, string, int or float first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDataError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3179781454.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmembers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/redis/commands/core.py\u001b[0m in \u001b[0;36msmembers\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   3382\u001b[0m         \u001b[0mFor\u001b[0m \u001b[0mmore\u001b[0m \u001b[0minformation\u001b[0m \u001b[0msee\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mredis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mcommands\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msmembers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3383\u001b[0m         \"\"\"\n\u001b[0;32m-> 3384\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SMEMBERS\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3386\u001b[0m     def smismember(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/redis/client.py\u001b[0m in \u001b[0;36mexecute_command\u001b[0;34m(self, *args, **options)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# COMMAND EXECUTION AND PROTOCOL PARSING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_execute_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/redis/client.py\u001b[0m in \u001b[0;36m_execute_command\u001b[0;34m(self, *args, **options)\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_connection_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m             return conn.retry.call_with_retry(\n\u001b[0m\u001b[1;32m    633\u001b[0m                 lambda: self._send_command_parse_response(\n\u001b[1;32m    634\u001b[0m                     \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/redis/retry.py\u001b[0m in \u001b[0;36mcall_with_retry\u001b[0;34m(self, do, fail)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_supported_errors\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                 \u001b[0mfailures\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/redis/client.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             return conn.retry.call_with_retry(\n\u001b[0;32m--> 633\u001b[0;31m                 lambda: self._send_command_parse_response(\n\u001b[0m\u001b[1;32m    634\u001b[0m                     \u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m                 ),\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/redis/client.py\u001b[0m in \u001b[0;36m_send_command_parse_response\u001b[0;34m(self, conn, command_name, *args, **options)\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mSend\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcommand\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \"\"\"\n\u001b[0;32m--> 603\u001b[0;31m         \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommand_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/redis/connection.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;34m\"\"\"Pack and send a command to the Redis server\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m         self.send_packed_command(\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_command_packer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0mcheck_health\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"check_health\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/redis/connection.py\u001b[0m in \u001b[0;36mpack\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m         \u001b[0mbuffer_cutoff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer_cutoff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m             \u001b[0;31m# to avoid large string mallocs, chunk the command into the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;31m# output list if we're sending large values or memoryviews\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/redis/_parsers/encoders.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;31m# a value we don't know how to deal with. throw an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mtypename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             raise DataError(\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0;34mf\"Invalid input of type: '{typename}'. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0;34mf\"Convert to a bytes, string, int or float first.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDataError\u001b[0m: Invalid input of type: 'set'. Convert to a bytes, string, int or float first."
          ]
        }
      ],
      "source": [
        "r.smembers(seen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "a26b4e97",
      "metadata": {
        "id": "a26b4e97",
        "outputId": "c090aa2b-87f2-42bf-fc97-00960544d0fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'queue_key' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1084293588.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'queue_key' is not defined"
          ]
        }
      ],
      "source": [
        "r.lrange(queue_key, 0, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520be26a",
      "metadata": {
        "id": "520be26a"
      },
      "outputs": [],
      "source": [
        "crawl_persistent()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4cd2bc27",
      "metadata": {
        "id": "4cd2bc27"
      },
      "source": [
        "## Stop words\n",
        "\n",
        "The most common English words are likely to appear on every page.\n",
        "They don't indicate what the page is about, and we might not want to index them. Words that we don't index are sometimes called [stop words](https://en.wikipedia.org/wiki/Stop_word).\n",
        "\n",
        "Once you have indexed a few pages, use the index to identify the words that have appeared the most times, totaled across all pages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f78d592",
      "metadata": {
        "tags": [],
        "id": "0f78d592"
      },
      "outputs": [],
      "source": [
        "word_key = 'Index:the'\n",
        "r.hvals(word_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91cb30d2",
      "metadata": {
        "tags": [],
        "id": "91cb30d2"
      },
      "outputs": [],
      "source": [
        "sum(int(x) for x in r.hvals(word_key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6fa99d6d",
      "metadata": {
        "tags": [],
        "id": "6fa99d6d"
      },
      "outputs": [],
      "source": [
        "counter = Counter()\n",
        "\n",
        "for word_key in r.keys('Index*'):\n",
        "    total = sum(int(x) for x in r.hvals(word_key))\n",
        "    word = word_key.decode().split(':')[1]\n",
        "    counter[word] = total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85dd22e",
      "metadata": {
        "tags": [],
        "id": "f85dd22e"
      },
      "outputs": [],
      "source": [
        "counter.most_common(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55fc1ac4",
      "metadata": {
        "id": "55fc1ac4"
      },
      "source": [
        "The following cells use the results to make a Zipf plot, which shows counts versus \"rank\" on a log-log scale (the most common word has rank 1, the next most common has rank 2, and so on).\n",
        "\n",
        "Zipf's law asserts that the distribution of word frequencies follows a power law, which implies that the Zipf plot is approximately a straight line."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730225d2",
      "metadata": {
        "id": "730225d2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "res = []\n",
        "\n",
        "for i, (word, count) in enumerate(counter.most_common()):\n",
        "    res.append((i+1, count))\n",
        "\n",
        "rank, count = np.transpose(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4053fe28",
      "metadata": {
        "id": "4053fe28"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(rank, count)\n",
        "plt.xlabel('Rank')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Zipf plot')\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "366c1c12",
      "metadata": {
        "id": "366c1c12"
      },
      "source": [
        "## Shutdown\n",
        "\n",
        "If you are running this notebook on your own computer, you can use the following command to shut down the Redis server.\n",
        "\n",
        "If you are running on Colab, it's not really necessary: the Redis server will get shut down when the Colab runtime shuts down (and everything stored in it will disappear)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2b82180",
      "metadata": {
        "id": "a2b82180"
      },
      "outputs": [],
      "source": [
        "!killall redis-server"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77911c35",
      "metadata": {
        "id": "77911c35"
      },
      "source": [
        "*Data Structures and Information Retrieval in Python*\n",
        "\n",
        "Copyright 2021 Allen Downey\n",
        "\n",
        "License: [Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Tags",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}